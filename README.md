
## ğŸ“¦ 4. `notebook-to-prod-template`
**Name:** `notebook-to-prod-template`
**Purpose:** Repo template that turns a Jupyter notebook into a FastAPI micro-service with CI, tests, and Helm chart.

# Notebook-to-Prod Template ğŸ“šâ¡ï¸ğŸš€

> GitHub template for converting research notebooks into production-ready microservices.

## ğŸš€ Features
- **Template repo:** boilerplate file structure & GitHub template link.
- **Notebook runner:** FastAPI app serving notebook cells as endpoints.
- **CI matrix:** test on multiple Python versions + linting.
- **Helm chart:** Kubernetes deployment with ConfigMap & Service.
- **Dependabot & Codecov** ready out of the box.

## ğŸ› ï¸ Tech Stack
- **Python:** FastAPI + nbclient
- **CI:** GitHub Actions matrix build + coverage upload
- **Container:** Dockerfile + multi-stage build
- **K8s:** Helm v3 chart (`charts/notebook-to-prod`)


## Code Structure
```
notebook-to-prod-template/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ notebook_service/           â† your Python package
â”‚       â”œâ”€â”€ __init__.py             # package marker
â”‚       â”œâ”€â”€ cli.py                  # consoleâ€script entrypoint (`notebook-cli`)
â”‚       â”œâ”€â”€ main.py                 # FastAPI app (`app = FastAPI()`)
â”‚       â”œâ”€â”€ runner.py               # notebookâ€execution logic (`run_notebook`)
â”‚       â”œâ”€â”€ emotion.py              # emotionâ€analysis helper functions
â”‚       â”œâ”€â”€ schemas.py              # Pydantic models / requestâ€response schemas
â”‚       â””â”€â”€ visualize.py
â”‚
â”œâ”€â”€ notebooks/                      # example Jupyter notebooks to execute
â”œâ”€â”€ data/                           # sample data files consumed by notebooks
â”‚
tests/
â”œâ”€â”€ conftest.py                  # shared fixtures / test setup
â”œâ”€â”€ notebook_service/
â”‚    â”œâ”€â”€ test_cli.py             â† your CLIâ€specific tests
â”‚    â”œâ”€â”€ test_emotion.py         â† NLP/emotion extraction
â”‚    â”œâ”€â”€ test_runner.py          â† core runner functions:
â”‚    â”‚     â€¢ load_data
â”‚    â”‚     â€¢ preprocess
â”‚    â”‚     â€¢ build_semantic_graph
â”‚    â”‚     â€¢ compute_centrality
â”‚    â”œâ”€â”€ test_visualization.py   â† optional, smokeâ€tests your graphâ€plotting funcs
â”‚    â””â”€â”€ test_main.py            â† FastAPI endpoint tests
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                 # GitHub Actions: lint, test, build steps
â”‚
â”œâ”€â”€ .pre-commit-config.yaml         # pre-commit hook definitions (Black, Flake8, etc.)
â”œâ”€â”€ docker-compose.yml              # Compose file for spinning up service(s)
â”œâ”€â”€ Dockerfile                      # container build instructions
â”œâ”€â”€ pyproject.toml                  # PEP 621 metadata, deps, build config, scripts
â”œâ”€â”€ README.md                       # overview, setup, usage, and project structure
â”œâ”€â”€ LICENSE                         # your chosen open-source license
â””â”€â”€ .gitignore                      # files/folders Git shouldnâ€™t track

```

## ğŸš€ Quick Start

# 1. Use as template
```bash
gh repo create my-project --template Br111t/notebook-to-prod-template
```
# 2. Edit notebook & endpoints
Fill in `example.ipynb` and update `notebook_service.py`

## 3. CI & Deploy

Push your changes and let GitHub Actions take care of the rest:

```bash
git add .
# work, commit, push to main...
git commit -m "Your meaningful commit message"
# when ready to cut a release:
git tag v1.1.0
git push origin main --tags
# now:
pip install .       # or build your package
python -c "import pkg_resources; print(pkg_resources.get_distribution('notebook-to-prod-template').version)"
# â†’ prints '1.1.0'

| Bump type | Version change example | What it signals                      |
| --------- | ---------------------- | ------------------------------------ |
| Patch     | `1.0.0 â†’ 1.0.1`        | Bug fixes, no new features           |
| Minor     | `1.0.1 â†’ 1.1.0`        | Backward-compatible new features     |
| Major     | `1.1.0 â†’ 2.0.0`        | Breaking changes, drop support, etc. |


```

# 4. Testing locally vs. in Docker

ğŸ–¥ï¸ Local (without Docker)
```bash
# 1) Create a venv
python -m venv .venv

# 2) Activate it
source .venv/bin/activate        # macOS/Linux
.\.venv\Scripts\Activate.ps1     # Windows PowerShell
# if you hit an execution-policy error on Windows:
#   Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned

# 3) Install your package (dev deps too, if desired)
pip install .[dev]              # includes pytest, flake8, etc.

# 4) Run tests
## Running Pre-commit Hooks & Tests
Before you commit, you can check code style and catch simple errors with **pre-commit**:

```bash
# Install pre-commit (if you haven't already):
pip install pre-commit

# Run all hooks against your staged files:
pre-commit run --all-files

# To run a specific hook, e.g. flake8:
pre-commit run flake8 --all-files
```

## To run your full test suite with pytest:
```bash
# From the repo root (venv activated if local):
pytest

# Show coverage report:
pytest --cov=notebook_service --cov-report=term-missing
```



# 5) Run your FastAPI service
```
uvicorn notebook_service.main:app --reload
```
FastAPI automatically mounts the interactive OpenAPI docs at:

Swagger UI:
http://127.0.0.1:8000/docs

ReDoc:
http://127.0.0.1:8000/redoc

ğŸ³ Using Docker
# 1) Build the image
docker build -t notebook-to-prod .

# 2) Run the container
docker run -p 8000:8000 notebook-to-prod

# 3) Exec into container and run tests (optional)
docker exec -it <container_id> pytest

Tip: If you need the docs inside Docker, expose the host and port:
```bash
docker run -p 8000:8000 notebook-to-prod uvicorn notebook_service.main:app --host 0.0.0.0
```
