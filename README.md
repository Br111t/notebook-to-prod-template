
## ğŸ“¦ 4. `notebook-to-prod-template`
**Name:** `notebook-to-prod-template`
**Purpose:** Repo template that turns a Jupyter notebook into a FastAPI micro-service with CI, tests, and Helm chart.

# Notebook-to-Prod Template ğŸ“šâ¡ï¸ğŸš€

> GitHub template for converting research notebooks into production-ready microservices.

## ğŸš€ Features
- **Template repo:** boilerplate file structure & GitHub template link.
- **Notebook runner:** FastAPI app serving notebook cells as endpoints.
- **CI matrix:** test on multiple Python versions + linting.
- **Helm chart:** Kubernetes deployment with ConfigMap & Service.
- **Dependabot & Codecov** ready out of the box.

## ğŸ› ï¸ Tech Stack
- **Python:** FastAPI + nbclient
- **CI:** GitHub Actions matrix build + coverage upload
- **Container:** Dockerfile + multi-stage build
- **K8s:** Helm v3 chart (`charts/notebook-to-prod`)


## Code Structure
```
notebook-to-prod-template/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ notebook_service/           â† your Python package
â”‚       â”œâ”€â”€ __init__.py             # package marker
â”‚       â”œâ”€â”€ cli.py                  # consoleâ€script entrypoint (`notebook-cli`)
â”‚       â”œâ”€â”€ main.py                 # FastAPI app (`app = FastAPI()`)
â”‚       â”œâ”€â”€ runner.py               # notebookâ€execution logic (`run_notebook`)
â”‚       â”œâ”€â”€ emotion.py              # emotionâ€analysis helper functions
â”‚       â”œâ”€â”€ schemas.py              # Pydantic models / requestâ€response schemas
â”‚       â””â”€â”€ visualize.py
â”‚
â”œâ”€â”€ notebooks/                      # example Jupyter notebooks to execute
â”œâ”€â”€ data/                           # sample data files consumed by notebooks
â”‚
tests/
â”œâ”€â”€ conftest.py                  # shared fixtures / test setup
â”œâ”€â”€ notebook_service/
â”‚    â”œâ”€â”€ test_cli.py             â† your CLIâ€specific tests
â”‚    â”œâ”€â”€ test_emotion.py         â† NLP/emotion extraction
â”‚    â”œâ”€â”€ test_runner.py          â† core runner functions:
â”‚    â”‚     â€¢ load_data
â”‚    â”‚     â€¢ preprocess
â”‚    â”‚     â€¢ build_semantic_graph
â”‚    â”‚     â€¢ compute_centrality
â”‚    â”œâ”€â”€ test_visualization.py   â† optional, smokeâ€tests your graphâ€plotting funcs
â”‚    â””â”€â”€ test_main.py            â† FastAPI endpoint tests
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml                 # GitHub Actions: lint, test, build steps
â”‚
â”œâ”€â”€ .pre-commit-config.yaml         # pre-commit hook definitions (Black, Flake8, etc.)
â”œâ”€â”€ docker-compose.yml              # Compose file for spinning up service(s)
â”œâ”€â”€ Dockerfile                      # container build instructions
â”œâ”€â”€ pyproject.toml                  # PEP 621 metadata, deps, build config, scripts
â”œâ”€â”€ README.md                       # overview, setup, usage, and project structure
â”œâ”€â”€ LICENSE                         # your chosen open-source license
â””â”€â”€ .gitignore                      # files/folders Git shouldnâ€™t track

```

## ğŸš€ Quick Start

# 1. Use as template
```bash
gh repo create my-project --template Br111t/notebook-to-prod-template
```
# 2. Edit notebook & endpoints
Fill in `example.ipynb` and update `notebook_service.py`

## 3. CI & Deploy

Push your changes and let GitHub Actions take care of the rest:

```bash
git add .
# work, commit, push to main...
git commit -m "Your meaningful commit message"
# when ready to cut a release:
git tag v1.1.0
git push origin main --tags
# now:
pip install .       # or build your package
python -c "import pkg_resources; print(pkg_resources.get_distribution('notebook-to-prod-template').version)"
# â†’ prints '1.1.0'
```

| Bump type | Version change example | What it signals                      |
| --------- | ---------------------- | ------------------------------------ |
| Patch     | `1.0.0 â†’ 1.0.1`        | Bug fixes, no new features           |
| Minor     | `1.0.1 â†’ 1.1.0`        | Backward-compatible new features     |
| Major     | `1.1.0 â†’ 2.0.0`        | Breaking changes, drop support, etc. |


## 4â€‚Testing & linting

### ğŸ–¥ï¸â€‚Local workflow (no Docker)

```bash
# 1) Create and activate a virtual-env
py -m venv .venv
# macOS / Linux
source .venv/bin/activate
# Windows PowerShell
.\.venv\Scripts\Activate.ps1      # Execution-policy error?  âœ  Set-ExecutionPolicy -Scope CurrentUser -ExecutionPolicy RemoteSigned

# copy your local .env into the venv
cp .env .venv/

# register your venv as a jupyter kernel
# with your .venv activated:
py -m ipykernel install --sys-prefix --name notebook-to-prod --display-name "Python (notebook-to-prod)"

```
Then in VS Codeâ€™s notebook kernel picker choose Python (notebook-to-prod)

```bash
# 2) Install the project  âœ  core + dev extras (pytest, flake8, nbqa, â€¦)
py -m pip install --upgrade pip
pip install ".[dev]"
pip-audit
```
```bash
# 3) Lint & format (pre-commit runs every hook once)
pre-commit run --all-files
```
```bash
# 4) Run tests
pytest -q                                    # terse
pytest --cov=notebook_service \
       --cov-report=term-missing             # coverage details
```

# 5) Run your FastAPI service
```
uvicorn notebook_service.main:app --reload
```
FastAPI automatically mounts the interactive OpenAPI docs at:

Swagger UI:
http://localhost:8000/docs

ReDoc:
http://localhost:8000/redoc

### ğŸ³ Using Docker
# 1) Build the image
docker build -t notebook-to-prod .

# 2) Run the container
docker run -p 8000:8000 --env-file .env notebook-to-prod

# 3) Exec into container and run tests (optional)
docker exec -it <container_id> pytest

Tip: If you need the docs inside Docker, expose the host and port:
```bash
docker run -p 8000:8000 notebook-to-prod uvicorn notebook_service.main:app --host 0.0.0.0
```
